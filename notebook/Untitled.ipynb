{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2627883-8b98-4ccd-aeef-d25079115870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Found 12 CSV files.\n",
      "/Users/sapthavarnidevineni/Downloads/2014-citibike-tripdata/4_April/201404-citibike-tripdata_1.csv\n",
      "/Users/sapthavarnidevineni/Downloads/2014-citibike-tripdata/12_December/201412-citibike-tripdata_1.csv\n",
      "/Users/sapthavarnidevineni/Downloads/2014-citibike-tripdata/11_November/201411-citibike-tripdata_1.csv\n",
      "/Users/sapthavarnidevineni/Downloads/2014-citibike-tripdata/7_July/201407-citibike-tripdata_1.csv\n",
      "/Users/sapthavarnidevineni/Downloads/2014-citibike-tripdata/10_October/201410-citibike-tripdata_1.csv\n",
      "/Users/sapthavarnidevineni/Downloads/2014-citibike-tripdata/9_September/201409-citibike-tripdata_1.csv\n",
      "/Users/sapthavarnidevineni/Downloads/2014-citibike-tripdata/8_August/201408-citibike-tripdata_1.csv\n",
      "/Users/sapthavarnidevineni/Downloads/2014-citibike-tripdata/6_June/201406-citibike-tripdata_1.csv\n",
      "/Users/sapthavarnidevineni/Downloads/2014-citibike-tripdata/3_March/201403-citibike-tripdata_1.csv\n",
      "/Users/sapthavarnidevineni/Downloads/2014-citibike-tripdata/1_January/201401-citibike-tripdata_1.csv\n",
      "/Users/sapthavarnidevineni/Downloads/2014-citibike-tripdata/2_February/201402-citibike-tripdata_1.csv\n",
      "/Users/sapthavarnidevineni/Downloads/2014-citibike-tripdata/5_May/201405-citibike-tripdata_1.csv\n",
      "‚úÖ Combined dataset shape: (8081216, 15)\n"
     ]
    }
   ],
   "source": [
    "#Step 1.1: Load and Merge All Monthly CSVs\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Correct folder path\n",
    "data_path = '/Users/sapthavarnidevineni/Downloads/2014-citibike-tripdata'\n",
    "\n",
    "# Recursively search for CSVs\n",
    "csv_files = glob(os.path.join(data_path, '**', '*.csv'), recursive=True)\n",
    "\n",
    "# Show what files were found\n",
    "print(f\"üîé Found {len(csv_files)} CSV files.\")\n",
    "for file in csv_files:\n",
    "    print(file)\n",
    "\n",
    "# Continue only if found\n",
    "if csv_files:\n",
    "    df_list = [pd.read_csv(f) for f in csv_files]\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    print(\"‚úÖ Combined dataset shape:\", df.shape)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Still no CSVs found. Try checking extensions (.txt?) or share a screenshot of folder contents.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12031ed2-85ad-4fff-9d22-f4809b30cf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid starttime values: 0\n",
      "Invalid stoptime values: 0\n",
      "‚úÖ Cleaned dataset shape (no rows dropped): (8081216, 16)\n"
     ]
    }
   ],
   "source": [
    "#Step 1.2: Clean and Preprocess the Data\n",
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Standardize column names (make lowercase, remove spaces)\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# ‚úÖ Convert time columns to datetime (allowing failed parsing)\n",
    "df['starttime'] = pd.to_datetime(df['starttime'], errors='coerce', format='mixed')\n",
    "df['stoptime'] = pd.to_datetime(df['stoptime'], errors='coerce', format='mixed')\n",
    "\n",
    "# ‚úÖ Add trip duration where timestamps are valid\n",
    "df['trip_duration_min'] = (df['stoptime'] - df['starttime']).dt.total_seconds() / 60\n",
    "\n",
    "# üìä Just show how many timestamps failed parsing (optional)\n",
    "print(\"Invalid starttime values:\", df['starttime'].isna().sum())\n",
    "print(\"Invalid stoptime values:\", df['stoptime'].isna().sum())\n",
    "\n",
    "print(\"‚úÖ Cleaned dataset shape (no rows dropped):\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23c41725-b64a-4611-83aa-deeaa75d9d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Stations:\n",
      "start_station_name\n",
      "8 Ave & W 31 St          100498\n",
      "Lafayette St & E 8 St     86692\n",
      "E 17 St & Broadway        80166\n",
      "Name: count, dtype: int64\n",
      "Filtered dataset shape (Top 3 stations): (267356, 16)\n"
     ]
    }
   ],
   "source": [
    "#Step 1.3: Select Top 3 Start Stations by Ride Count\n",
    "top_stations = df['start_station_name'].value_counts().head(3)\n",
    "print(\"Top 3 Stations:\")\n",
    "print(top_stations)\n",
    "\n",
    "# Filter dataset for top 3 stations only\n",
    "top_station_names = top_stations.index.tolist()\n",
    "df_top3 = df[df['start_station_name'].isin(top_station_names)]\n",
    "\n",
    "print(\"Filtered dataset shape (Top 3 stations):\", df_top3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0663939c-bf8b-48dd-b8a5-c2a330007ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 15:22:25,641 INFO: Initializing external client\n",
      "2025-05-09 15:22:25,642 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-05-09 15:22:26,688 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "Uploading Dataframe: 95.52% |‚ñâ| Rows 255369/267356 | Elapsed Time: 03:18 | Remai%6|1746818752.033|FAIL|rdkafka#producer-1| [thrd:ssl://51.161.80.189:9093/0]: ssl://51.161.80.189:9093/0: Disconnected (after 200026ms in state UP)\n",
      "Uploading Dataframe: 100.00% |‚ñà| Rows 267356/267356 | Elapsed Time: 03:25 | Rema\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: citibike_2014_top3_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1225937/jobs/named/citibike_2014_top3_1_offline_fg_materialization/executions\n",
      "2025-05-09 15:26:05,662 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-05-09 15:26:08,747 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-05-09 15:28:34,642 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-05-09 15:28:34,733 INFO: Waiting for log aggregation to finish.\n",
      "2025-05-09 15:28:43,045 INFO: Execution finished successfully.\n",
      "‚úÖ Data successfully inserted into Hopsworks Feature Store.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "# Step 1: Login\n",
    "project = hopsworks.login(\n",
    "    api_key_value=\"HB0zAW5eEzl4iuNq.KJX5bZAdAnGaRJrIFVFVB30exr8wMMql5TZUuNMVeMUbcOVqRXg0fW3OWz2aRzOi\",\n",
    "    project=\"CDA500FINAL\"\n",
    ")\n",
    "\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "# Step 2: Clean object (string) columns\n",
    "for col in df_top3.select_dtypes(include='object').columns:\n",
    "    df_top3[col] = df_top3[col].astype(str).fillna('')\n",
    "\n",
    "# Optional: Fill numerical NaNs (if you want)\n",
    "# df_top3 = df_top3.fillna(0)\n",
    "\n",
    "# Step 3: Create or Get Feature Group\n",
    "from hsfs.feature_group import FeatureGroup\n",
    "\n",
    "fg = fs.get_or_create_feature_group(\n",
    "    name=\"citibike_2014_top3\",\n",
    "    version=1,\n",
    "    description=\"Citi Bike 2014 rides for top 3 start stations\",\n",
    "    primary_key=[\"starttime\", \"start_station_name\"],\n",
    "    event_time=\"starttime\"\n",
    ")\n",
    "\n",
    "# Step 4: Insert into Hopsworks\n",
    "fg.insert(df_top3, write_options={\"wait_for_job\": True})\n",
    "\n",
    "print(\"‚úÖ Data successfully inserted into Hopsworks Feature Store.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6e849f6-bd6d-4c15-9a36-de698c6000f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DagsHub token saved to ~/.netrc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "netrc_path = os.path.expanduser(\"~/.netrc\")\n",
    "with open(netrc_path, \"w\") as f:\n",
    "    f.write(\"\"\"machine dagshub.com\n",
    "login dsapthavarni\n",
    "password af783d5cf1e2bc107ae9ce02b1af20612fc6c3c9\n",
    "\"\"\")\n",
    "\n",
    "os.chmod(netrc_path, 0o600)\n",
    "print(\"‚úÖ DagsHub token saved to ~/.netrc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "572277cd-2671-4ba3-b86b-6ea1f7c3ec5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/09 23:39:13 INFO mlflow.tracking.fluent: Experiment with name 'citi-bike-trip-prediction' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/2add5aa706534654a26588936ea3bc2f', creation_time=1746848353832, experiment_id='0', last_update_time=1746848353832, lifecycle_stage='active', name='citi-bike-trip-prediction', tags={}>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/dsapthavarni/CDA500BIKE.mlflow\")\n",
    "mlflow.set_experiment(\"citi-bike-trip-prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d703752-7ae6-47a7-8442-9936cff1fa75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">‚ùó‚ùó‚ùó AUTHORIZATION REQUIRED ‚ùó‚ùó‚ùó</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                       \u001b[1m‚ùó‚ùó‚ùó AUTHORIZATION REQUIRED ‚ùó‚ùó‚ùó\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Open the following link in your browser to authorize the client:\n",
      "https://dagshub.com/login/oauth/authorize?state=b2170373-262e-4f79-8890-b28ea0f498e7&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=92b86de6a821f062bb441cb1dc4da79bb85a43f02f1d53b2424b5d879c46a28e\n",
      "\n",
      "\n",
      "2025-05-09 23:41:23,081 INFO: HTTP Request: POST https://dagshub.com/login/oauth/middleman \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 23:41:23,230 INFO: HTTP Request: POST https://dagshub.com/login/oauth/access_token \"HTTP/1.1 200 OK\"\n",
      "2025-05-09 23:41:23,377 INFO: HTTP Request: GET https://dagshub.com/api/v1/user \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as dsapthavarni\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as dsapthavarni\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 23:41:23,385 INFO: Accessing as dsapthavarni\n",
      "2025-05-09 23:41:23,562 INFO: HTTP Request: GET https://dagshub.com/api/v1/repos/dsapthavarni/CDA500BIKE \"HTTP/1.1 200 OK\"\n",
      "2025-05-09 23:41:23,714 INFO: HTTP Request: GET https://dagshub.com/api/v1/user \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"dsapthavarni/CDA500BIKE\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"dsapthavarni/CDA500BIKE\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 23:41:23,719 INFO: Initialized MLflow to track repo \"dsapthavarni/CDA500BIKE\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository dsapthavarni/CDA500BIKE initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository dsapthavarni/CDA500BIKE initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 23:41:23,722 INFO: Repository dsapthavarni/CDA500BIKE initialized!\n"
     ]
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='dsapthavarni', repo_name='CDA500BIKE', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43af7d26-3e90-41c0-ba90-2123d4d227c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 23:43:58,154 INFO: HTTP Request: GET https://dagshub.com/api/v1/repos/dsapthavarni/CDA500BIKE \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"dsapthavarni/CDA500BIKE\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"dsapthavarni/CDA500BIKE\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 23:43:58,160 INFO: Initialized MLflow to track repo \"dsapthavarni/CDA500BIKE\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository dsapthavarni/CDA500BIKE initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository dsapthavarni/CDA500BIKE initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 23:43:58,162 INFO: Repository dsapthavarni/CDA500BIKE initialized!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Baseline MAE logged to MLflow: 53.293\n",
      "üèÉ View run baseline_naive_lag at: https://dagshub.com/dsapthavarni/CDA500BIKE.mlflow/#/experiments/0/runs/b84d1a92823a41fa92549b1edf791834\n",
      "üß™ View experiment at: https://dagshub.com/dsapthavarni/CDA500BIKE.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Step 0: Import Required Modules\n",
    "# -----------------------------\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from dagshub import dagshub_logger\n",
    "import dagshub\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# -----------------------------\n",
    "# Step 1: Init DagsHub + MLflow\n",
    "# -----------------------------\n",
    "dagshub.init(repo_owner='dsapthavarni', repo_name='CDA500BIKE', mlflow=True)\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/dsapthavarni/CDA500BIKE.mlflow\")\n",
    "mlflow.set_experiment(\"citi-bike-trip-prediction\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Create Daily Lag Features (1 to 28)\n",
    "# -----------------------------\n",
    "df_top3['starttime'] = pd.to_datetime(df_top3['starttime'])\n",
    "df_top3['date'] = df_top3['starttime'].dt.date\n",
    "\n",
    "# Get daily trip counts per station\n",
    "daily_counts = df_top3.groupby(['start_station_name', 'date']).size().reset_index(name='trip_count')\n",
    "\n",
    "# Sort properly\n",
    "daily_counts = daily_counts.sort_values(['start_station_name', 'date'])\n",
    "\n",
    "# Create lag features\n",
    "for lag in range(1, 29):\n",
    "    daily_counts[f'lag_{lag}'] = (\n",
    "        daily_counts.groupby('start_station_name')['trip_count'].shift(lag)\n",
    "    )\n",
    "\n",
    "# Drop rows with NaNs in lag features\n",
    "daily_lagged = daily_counts.dropna().reset_index(drop=True)\n",
    "\n",
    "# Ensure 'date' column is datetime for filtering\n",
    "daily_lagged['date'] = pd.to_datetime(daily_lagged['date'])\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Train-Test Split (last 14 days = test)\n",
    "# -----------------------------\n",
    "cutoff_date = daily_lagged['date'].max() - pd.Timedelta(days=14)\n",
    "train_df = daily_lagged[daily_lagged['date'] <= cutoff_date]\n",
    "test_df = daily_lagged[daily_lagged['date'] > cutoff_date]\n",
    "\n",
    "# -----------------------------\n",
    "# Step 4: Baseline Model (Naive Lag 1)\n",
    "# -----------------------------\n",
    "y_true = test_df['trip_count'].values\n",
    "y_pred = test_df['lag_1'].values\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 5: Log to DagsHub MLflow\n",
    "# -----------------------------\n",
    "with mlflow.start_run(run_name=\"baseline_naive_lag\"):\n",
    "    mlflow.log_param(\"model_type\", \"Naive Lag-1\")\n",
    "    mlflow.log_param(\"lag_used\", 1)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.set_tag(\"step\", \"baseline\")\n",
    "    \n",
    "    print(f\"‚úÖ Baseline MAE logged to MLflow: {mae:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "388482cd-ee96-4fd2-a424-ae5307f5b981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a28be354-c4cd-49fb-a308-4918c9ef439a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 23:47:46,125 INFO: HTTP Request: GET https://dagshub.com/api/v1/repos/dsapthavarni/CDA500BIKE \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"dsapthavarni/CDA500BIKE\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"dsapthavarni/CDA500BIKE\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 23:47:46,129 INFO: Initialized MLflow to track repo \"dsapthavarni/CDA500BIKE\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository dsapthavarni/CDA500BIKE initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository dsapthavarni/CDA500BIKE initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 23:47:46,130 INFO: Repository dsapthavarni/CDA500BIKE initialized!\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7140\n",
      "[LightGBM] [Info] Number of data points in the train set: 969, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 262.987616\n",
      "‚úÖ LightGBM MAE logged: 64.984\n",
      "üèÉ View run lightgbm_28_lags at: https://dagshub.com/dsapthavarni/CDA500BIKE.mlflow/#/experiments/0/runs/905bb8792f6447abb778ed9f5a97d9be\n",
      "üß™ View experiment at: https://dagshub.com/dsapthavarni/CDA500BIKE.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Step 1: Import Dependencies\n",
    "# -----------------------------\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "import dagshub\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Init DagsHub + MLflow (if not already done)\n",
    "# -----------------------------\n",
    "dagshub.init(repo_owner='dsapthavarni', repo_name='CDA500BIKE', mlflow=True)\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/dsapthavarni/CDA500BIKE.mlflow\")\n",
    "mlflow.set_experiment(\"citi-bike-trip-prediction\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Define features and target\n",
    "# -----------------------------\n",
    "feature_cols = [f'lag_{i}' for i in range(1, 29)]\n",
    "target_col = 'trip_count'\n",
    "\n",
    "X = daily_lagged[feature_cols]\n",
    "y = daily_lagged[target_col]\n",
    "\n",
    "# Use the same 14-day holdout as before\n",
    "X_train = X[daily_lagged['date'] <= cutoff_date]\n",
    "X_test = X[daily_lagged['date'] > cutoff_date]\n",
    "y_train = y[daily_lagged['date'] <= cutoff_date]\n",
    "y_test = y[daily_lagged['date'] > cutoff_date]\n",
    "\n",
    "# -----------------------------\n",
    "# Step 4: Train LightGBM Model\n",
    "# -----------------------------\n",
    "with mlflow.start_run(run_name=\"lightgbm_28_lags\"):\n",
    "\n",
    "    model = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # Log parameters and metric\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM\")\n",
    "    mlflow.log_param(\"features_used\", 28)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.set_tag(\"step\", \"lightgbm_full\")\n",
    "\n",
    "    print(f\"‚úÖ LightGBM MAE logged: {mae:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "642d2b0b-e500-4c1b-b3e9-265f2a4864e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîù Top 10 Features: ['lag_1', 'lag_11', 'lag_28', 'lag_20', 'lag_6', 'lag_14', 'lag_7', 'lag_18', 'lag_21', 'lag_17']\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 969, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 262.987616\n",
      "‚úÖ LightGBM (Top 10 features) MAE: 57.681\n",
      "üèÉ View run lightgbm_top10_features at: https://dagshub.com/dsapthavarni/CDA500BIKE.mlflow/#/experiments/0/runs/d3e00ebf30c34b77a508852f0807e4dc\n",
      "üß™ View experiment at: https://dagshub.com/dsapthavarni/CDA500BIKE.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Step 1: Get Feature Importances from Full Model\n",
    "# -----------------------------\n",
    "import numpy as np\n",
    "\n",
    "# Reuse previously trained model from Step 2B\n",
    "importances = model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Select top 10 most important lag features\n",
    "top10_features = feature_importance_df['feature'].iloc[:10].tolist()\n",
    "print(\"üîù Top 10 Features:\", top10_features)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Train-Test Split with Top 10 Features\n",
    "# -----------------------------\n",
    "X_top10 = daily_lagged[top10_features]\n",
    "\n",
    "X_train_top10 = X_top10[daily_lagged['date'] <= cutoff_date]\n",
    "X_test_top10 = X_top10[daily_lagged['date'] > cutoff_date]\n",
    "y_train_top10 = y[daily_lagged['date'] <= cutoff_date]\n",
    "y_test_top10 = y[daily_lagged['date'] > cutoff_date]\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Train & Log to MLflow\n",
    "# -----------------------------\n",
    "with mlflow.start_run(run_name=\"lightgbm_top10_features\"):\n",
    "\n",
    "    model_top10 = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    model_top10.fit(X_train_top10, y_train_top10)\n",
    "\n",
    "    y_pred_top10 = model_top10.predict(X_test_top10)\n",
    "    mae_top10 = mean_absolute_error(y_test_top10, y_pred_top10)\n",
    "\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM\")\n",
    "    mlflow.log_param(\"features_used\", top10_features)\n",
    "    mlflow.log_metric(\"mae\", mae_top10)\n",
    "    mlflow.set_tag(\"step\", \"lightgbm_top10\")\n",
    "\n",
    "    print(f\"‚úÖ LightGBM (Top 10 features) MAE: {mae_top10:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aece50f5-8b84-4b1a-9c29-3d4f0331dd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 00:28:01,613 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "Copy your Api Key (first register/login): https://c.app.hopsworks.ai/account/api/generated\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Paste it here:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 00:28:27,772 INFO: Initializing external client\n",
      "2025-05-10 00:28:27,773 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-05-10 00:28:29,041 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225937\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (20.91s) \n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1225937/fs/1213520/fg/1454556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà| Rows 1010/1010 | Elapsed Time: 00:00 | Remainin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: citibike_daily_lagged_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1225937/jobs/named/citibike_daily_lagged_1_offline_fg_materialization/executions\n",
      "2025-05-10 00:29:08,501 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-05-10 00:29:11,665 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-05-10 00:31:23,319 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-05-10 00:31:23,397 INFO: Waiting for log aggregation to finish.\n",
      "2025-05-10 00:31:51,475 INFO: Execution finished successfully.\n",
      "‚úÖ Feature engineering complete and stored in Hopsworks.\n"
     ]
    }
   ],
   "source": [
    "#feature_engineering.py\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "\n",
    "# -----------------------------\n",
    "# Step 1: Connect to Hopsworks\n",
    "# -----------------------------\n",
    "project = hopsworks.login(project=\"CDA500FINAL\")\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Load top 3 station data\n",
    "# -----------------------------\n",
    "fg_raw = fs.get_feature_group(\"citibike_2014_top3\", version=1)\n",
    "df = fg_raw.read()\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Prepare daily trip counts\n",
    "# -----------------------------\n",
    "df['starttime'] = pd.to_datetime(df['starttime'])\n",
    "df['date'] = df['starttime'].dt.date\n",
    "\n",
    "daily_counts = (\n",
    "    df.groupby(['start_station_name', 'date'])\n",
    "    .size()\n",
    "    .reset_index(name='trip_count')\n",
    "    .sort_values(['start_station_name', 'date'])\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 4: Create 28-day lag features\n",
    "# -----------------------------\n",
    "for lag in range(1, 29):\n",
    "    daily_counts[f'lag_{lag}'] = (\n",
    "        daily_counts.groupby('start_station_name')['trip_count'].shift(lag)\n",
    "    )\n",
    "\n",
    "# Drop rows with incomplete lag history\n",
    "daily_lagged = daily_counts.dropna().reset_index(drop=True)\n",
    "\n",
    "# Add timestamp column for Hopsworks event_time\n",
    "daily_lagged['date'] = pd.to_datetime(daily_lagged['date'])\n",
    "\n",
    "# -----------------------------\n",
    "# Step 5: Write to Hopsworks Feature Store\n",
    "# -----------------------------\n",
    "fg_lagged = fs.get_or_create_feature_group(\n",
    "    name=\"citibike_daily_lagged\",\n",
    "    version=1,\n",
    "    primary_key=[\"date\", \"start_station_name\"],\n",
    "    event_time=\"date\",\n",
    "    description=\"Daily trip counts with 28 lag features for top 3 stations\"\n",
    ")\n",
    "\n",
    "fg_lagged.insert(daily_lagged, write_options={\"wait_for_job\": True})\n",
    "\n",
    "print(\"‚úÖ Feature engineering complete and stored in Hopsworks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "023c69af-dac6-4f3f-aeab-dfb417f2db98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 00:39:31,735 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 00:39:34,744 INFO: Initializing external client\n",
      "2025-05-10 00:39:34,744 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-05-10 00:39:35,353 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225937\n",
      "2025-05-10 00:39:36,175 INFO: HTTP Request: GET https://dagshub.com/api/v1/repos/dsapthavarni/CDA500BIKE \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"dsapthavarni/CDA500BIKE\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"dsapthavarni/CDA500BIKE\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 00:39:36,180 INFO: Initialized MLflow to track repo \"dsapthavarni/CDA500BIKE\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository dsapthavarni/CDA500BIKE initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository dsapthavarni/CDA500BIKE initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 00:39:36,182 INFO: Repository dsapthavarni/CDA500BIKE initialized!\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.52s) \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000955 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7114\n",
      "[LightGBM] [Info] Number of data points in the train set: 969, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 259.925697\n",
      "‚úÖ Model trained. MAE: 64.872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ProvenanceWarning: Model schema cannot not be inferred without both the feature view and the training dataset version.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5815b5f1435449318ede8274b281863d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47228f21111446282e1eabd8f60e56e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/sapthavarnidevineni/CDA 500 final project/best_model.pkl: 0.000%|          | 0/272149 elapsed‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446575afe32c4a9e99f0fa411e3f598d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/sapthavarnidevineni/CDA 500 final project/input_example.json: 0.000%|          | 0/183 elapse‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/1225937/models/citibike_predictor/1\n",
      "‚úÖ Model registered and saved to Hopsworks.\n",
      "üèÉ View run lightgbm_28lags_final at: https://dagshub.com/dsapthavarni/CDA500BIKE.mlflow/#/experiments/0/runs/6d8c1a5408fc44b0863f078f0bf4475b\n",
      "üß™ View experiment at: https://dagshub.com/dsapthavarni/CDA500BIKE.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "#train_model.py\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import joblib\n",
    "import hopsworks\n",
    "import mlflow\n",
    "import dagshub\n",
    "\n",
    "# -----------------------------\n",
    "# Step 1: Connect to Hopsworks & MLflow\n",
    "# -----------------------------\n",
    "project = hopsworks.login(project=\"CDA500FINAL\")\n",
    "fs = project.get_feature_store()\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# DagsHub + MLflow\n",
    "dagshub.init(repo_owner=\"dsapthavarni\", repo_name=\"CDA500BIKE\", mlflow=True)\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/dsapthavarni/CDA500BIKE.mlflow\")\n",
    "mlflow.set_experiment(\"citi-bike-trip-prediction\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Load lagged features\n",
    "# -----------------------------\n",
    "fg = fs.get_feature_group(\"citibike_daily_lagged\", version=1)\n",
    "df = fg.read()\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Prepare data\n",
    "# -----------------------------\n",
    "feature_cols = [f'lag_{i}' for i in range(1, 29)]\n",
    "target_col = 'trip_count'\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "cutoff = df['date'].max() - pd.Timedelta(days=14)\n",
    "\n",
    "X_train = X[df['date'] <= cutoff]\n",
    "X_test = X[df['date'] > cutoff]\n",
    "y_train = y[df['date'] <= cutoff]\n",
    "y_test = y[df['date'] > cutoff]\n",
    "\n",
    "# -----------------------------\n",
    "# Step 4: Train and log model\n",
    "# -----------------------------\n",
    "with mlflow.start_run(run_name=\"lightgbm_28lags_final\"):\n",
    "    model = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # Log to MLflow\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM\")\n",
    "    mlflow.log_param(\"features_used\", 28)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "    print(f\"‚úÖ Model trained. MAE: {mae:.3f}\")\n",
    "\n",
    "    # Save model locally\n",
    "    joblib.dump(model, \"best_model.pkl\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Step 5: Register model in Hopsworks\n",
    "    # -----------------------------\n",
    "    model_obj = mr.python.create_model(\n",
    "        name=\"citibike_predictor\",\n",
    "        metrics={\"mae\": float(mae)},\n",
    "        description=\"LightGBM with 28 lag features for Citi Bike trip prediction\",\n",
    "        input_example=X_test.head(1)\n",
    "    )\n",
    "\n",
    "    model_obj.save(\"best_model.pkl\")\n",
    "    print(\"‚úÖ Model registered and saved to Hopsworks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06bf97c7-8f9f-4d6d-8fcc-0fcefbefe5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 00:43:10,148 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 00:43:13,157 INFO: Initializing external client\n",
      "2025-05-10 00:43:13,157 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-05-10 00:43:14,129 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225937\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.54s) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f643a014d25b495c9e39c47a90f80ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/272149 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at NE\n",
      "https://c.app.hopsworks.ai:443/p/1225937/fs/1213520/fg/1454560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà| Rows 3/3 | Elapsed Time: 00:00 | Remaining Time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: citibike_predictions_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1225937/jobs/named/citibike_predictions_1_offline_fg_materialization/executions\n",
      "2025-05-10 00:43:30,473 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-05-10 00:43:33,639 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-05-10 00:45:07,526 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-05-10 00:45:07,703 INFO: Waiting for log aggregation to finish.\n",
      "2025-05-10 00:45:19,446 INFO: Execution finished successfully.\n",
      "‚úÖ Inference complete. Predictions saved to Hopsworks.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import hopsworks\n",
    "import joblib\n",
    "from datetime import timedelta\n",
    "\n",
    "# -----------------------------\n",
    "# Step 1: Connect to Hopsworks\n",
    "# -----------------------------\n",
    "project = hopsworks.login(project=\"CDA500FINAL\")\n",
    "fs = project.get_feature_store()\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Load latest lag features\n",
    "# -----------------------------\n",
    "fg_lagged = fs.get_feature_group(\"citibike_daily_lagged\", version=1)\n",
    "df = fg_lagged.read()\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Get the most recent day's features\n",
    "latest_date = df['date'].max()\n",
    "today_data = df[df['date'] == latest_date]\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Load registered model\n",
    "# -----------------------------\n",
    "model = mr.get_model(\"citibike_predictor\", version=1)\n",
    "model_dir = model.download()\n",
    "model = joblib.load(f\"{model_dir}/best_model.pkl\")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 4: Predict next-day trip counts\n",
    "# -----------------------------\n",
    "feature_cols = [f'lag_{i}' for i in range(1, 29)]\n",
    "X_today = today_data[feature_cols]\n",
    "predictions = model.predict(X_today)\n",
    "\n",
    "# Create prediction DataFrame\n",
    "next_day = latest_date + timedelta(days=1)\n",
    "prediction_df = pd.DataFrame({\n",
    "    \"date\": next_day,\n",
    "    \"start_station_name\": today_data[\"start_station_name\"].values,\n",
    "    \"predicted_trip_count\": predictions\n",
    "})\n",
    "\n",
    "# -----------------------------\n",
    "# Step 5: Insert predictions into Hopsworks\n",
    "# -----------------------------\n",
    "fg_pred = fs.get_or_create_feature_group(\n",
    "    name=\"citibike_predictions\",\n",
    "    version=1,\n",
    "    primary_key=[\"date\", \"start_station_name\"],\n",
    "    event_time=\"date\",\n",
    "    description=\"Predicted trip counts for next day using LightGBM\"\n",
    ")\n",
    "\n",
    "fg_pred.insert(prediction_df, write_options={\"wait_for_job\": True})\n",
    "print(\"‚úÖ Inference complete. Predictions saved to Hopsworks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88168c6-4fdc-48b6-b523-e296e892e837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
